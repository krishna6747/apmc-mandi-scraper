{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZlP-GTr8AfCe","executionInfo":{"status":"ok","timestamp":1756362237747,"user_tz":-330,"elapsed":41260,"user":{"displayName":"Krishna Vishwakarma","userId":"04672623043770161009"}},"outputId":"8894bae0-30c4-4df6-c7ba-bf7011d7538d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting selenium\n","  Downloading selenium-4.35.0-py3-none-any.whl.metadata (7.4 kB)\n","Collecting webdriver-manager\n","  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n","Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n","Collecting trio~=0.30.0 (from selenium)\n","  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n","Collecting trio-websocket~=0.12.2 (from selenium)\n","  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.8.3)\n","Collecting typing_extensions~=4.14.0 (from selenium)\n","  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (2.32.4)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (1.1.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (25.0)\n","Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (3.10)\n","Collecting outcome (from trio~=0.30.0->selenium)\n","  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n","Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium)\n","  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->webdriver-manager) (3.4.3)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n","Downloading selenium-4.35.0-py3-none-any.whl (9.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n","Downloading trio-0.30.0-py3-none-any.whl (499 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n","Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n","Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Installing collected packages: wsproto, typing_extensions, outcome, webdriver-manager, trio, trio-websocket, selenium\n","  Attempting uninstall: typing_extensions\n","    Found existing installation: typing_extensions 4.15.0\n","    Uninstalling typing_extensions-4.15.0:\n","      Successfully uninstalled typing_extensions-4.15.0\n","Successfully installed outcome-1.3.0.post0 selenium-4.35.0 trio-0.30.0 trio-websocket-0.12.2 typing_extensions-4.14.1 webdriver-manager-4.0.2 wsproto-1.2.0\n","Hit:1 https://cli.github.com/packages stable InRelease\n","Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n","Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,199 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,519 kB]\n","Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,782 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,576 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,606 kB]\n","Fetched 23.1 MB in 3s (7,455 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  apparmor chromium-browser libfuse3-3 libudev1 snapd squashfs-tools\n","  systemd-hwe-hwdb udev\n","Suggested packages:\n","  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n","The following NEW packages will be installed:\n","  apparmor chromium-browser chromium-chromedriver libfuse3-3 snapd\n","  squashfs-tools systemd-hwe-hwdb udev\n","The following packages will be upgraded:\n","  libudev1\n","1 upgraded, 8 newly installed, 0 to remove and 36 not upgraded.\n","Need to get 32.5 MB of archives.\n","After this operation, 130 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.4 [598 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.16 [76.7 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.16 [1,557 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.68.5+ubuntu22.04.1 [30.0 MB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n","Fetched 32.5 MB in 1s (25.4 MB/s)\n","Preconfiguring packages ...\n","Selecting previously unselected package apparmor.\n","(Reading database ... 126371 files and directories currently installed.)\n","Preparing to unpack .../apparmor_3.0.4-2ubuntu2.4_amd64.deb ...\n","Unpacking apparmor (3.0.4-2ubuntu2.4) ...\n","Selecting previously unselected package squashfs-tools.\n","Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n","Unpacking squashfs-tools (1:4.5-3build1) ...\n","Preparing to unpack .../libudev1_249.11-0ubuntu3.16_amd64.deb ...\n","Unpacking libudev1:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...\n","Setting up libudev1:amd64 (249.11-0ubuntu3.16) ...\n","Selecting previously unselected package udev.\n","(Reading database ... 126571 files and directories currently installed.)\n","Preparing to unpack .../udev_249.11-0ubuntu3.16_amd64.deb ...\n","Unpacking udev (249.11-0ubuntu3.16) ...\n","Selecting previously unselected package libfuse3-3:amd64.\n","Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n","Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n","Selecting previously unselected package snapd.\n","Preparing to unpack .../snapd_2.68.5+ubuntu22.04.1_amd64.deb ...\n","Unpacking snapd (2.68.5+ubuntu22.04.1) ...\n","Setting up apparmor (3.0.4-2ubuntu2.4) ...\n","Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n","Setting up squashfs-tools (1:4.5-3build1) ...\n","Setting up udev (249.11-0ubuntu3.16) ...\n","invoke-rc.d: could not determine current runlevel\n","invoke-rc.d: policy-rc.d denied execution of start.\n","Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n","Setting up snapd (2.68.5+ubuntu22.04.1) ...\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n","Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n","Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n","Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n","Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n","Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n","Selecting previously unselected package chromium-browser.\n","(Reading database ... 126798 files and directories currently installed.)\n","Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n","=> Installing the chromium snap\n","==> Checking connectivity with the snap store\n","===> System doesn't have a working snapd, skipping\n","Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","Selecting previously unselected package chromium-chromedriver.\n","Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n","Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","Selecting previously unselected package systemd-hwe-hwdb.\n","Preparing to unpack .../systemd-hwe-hwdb_249.11.5_all.deb ...\n","Unpacking systemd-hwe-hwdb (249.11.5) ...\n","Setting up systemd-hwe-hwdb (249.11.5) ...\n","Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n","Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","Processing triggers for udev (249.11-0ubuntu3.16) ...\n","Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n","\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n","cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"]}],"source":["\n","!pip install selenium webdriver-manager pandas beautifulsoup4\n","!apt-get update\n","!apt install chromium-chromedriver\n","!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1165,"status":"ok","timestamp":1756362249327,"user":{"displayName":"Krishna Vishwakarma","userId":"04672623043770161009"},"user_tz":-330},"id":"zP5Di-rCB5Y7"},"outputs":[],"source":["import time\n","import pandas as pd\n","import tempfile\n","from selenium import webdriver\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.support.ui import Select, WebDriverWait\n","from selenium.webdriver.support import expected_conditions as EC\n","from selenium.webdriver.chrome.options import Options\n","from selenium.common.exceptions import TimeoutException, NoSuchElementException"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kFb7oh9IEkUW","outputId":"3e21295d-cea0-4188-c9db-a274633729b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["🚀 Starting complete Gujarat eNAM data extraction...\n","⚠️  This will take considerable time as it processes ALL districts and mandis\n","✓ Driver setup successful!\n","Starting step-by-step scrape for Gujarat...\n","✓ Selected language: English\n","✓ Found state dropdown at index 1\n","✓ Selected state: Gujarat\n","✓ Found 33 districts\n","Found 33 districts to process\n","\n","--- Processing District 1/33: Ahmedabad ---\n","  Selecting Ahmedabad...\n","  ✓ Selected Ahmedabad, extracting data...\n","  ! No data found at district level\n","    Found 7 mandis in Ahmedabad\n","      Processing mandi 1/7: Ahmedabad\n","      ✓ Table extraction: Ahmedabad\n","        ✓ Extracted 1 records for Ahmedabad\n","      Processing mandi 2/7: Bavla\n","      ✓ Table extraction: Bavla\n","        ✓ Extracted 1 records for Bavla\n","      Processing mandi 3/7: Dhandhuka\n"]}],"source":["class FocusedEnamScraper:\n","    def __init__(self):\n","        self.driver = None\n","        self.wait = None\n","        self.data = []\n","        self.setup_driver()\n","\n","    def setup_driver(self):\n","        \"\"\"Setup Chrome driver\"\"\"\n","        chrome_options = Options()\n","        chrome_options.add_argument(\"--headless\")\n","        chrome_options.add_argument(\"--no-sandbox\")\n","        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n","        chrome_options.add_argument(\"--disable-gpu\")\n","        chrome_options.add_argument(\"--window-size=1920,1080\")\n","\n","        temp_dir = tempfile.mkdtemp(prefix='chrome_user_data_')\n","        chrome_options.add_argument(f\"--user-data-dir={temp_dir}\")\n","\n","        try:\n","            self.driver = webdriver.Chrome(options=chrome_options)\n","            self.wait = WebDriverWait(self.driver, 15)\n","            print(\"✓ Driver setup successful!\")\n","        except Exception as e:\n","            print(f\"Driver setup failed: {e}\")\n","            raise\n","\n","    def scrape_step_by_step(self, state=\"Gujarat\", max_districts=None):\n","        \"\"\"Scrape data step by step with detailed extraction at each level\"\"\"\n","        try:\n","            print(f\"Starting step-by-step scrape for {state}...\")\n","            self.driver.get(\"https://enam.gov.in/web/apmc-contact-details\")\n","            time.sleep(5)\n","\n","            # Step 1: Select English language\n","            self.select_language(\"English\")\n","\n","            # Step 2: Select state\n","            state_success = self.select_state(state)\n","            if not state_success:\n","                return self.data\n","\n","            # Step 3: Get and process districts\n","            districts = self.get_available_districts()\n","            print(f\"Found {len(districts)} districts to process\")\n","\n","            # Process all districts if max_districts is None\n","            districts_to_process = districts if max_districts is None else districts[:max_districts]\n","\n","            for i, district in enumerate(districts_to_process):\n","                print(f\"\\n--- Processing District {i+1}/{len(districts_to_process)}: {district} ---\")\n","\n","                # Select district and extract data\n","                self.process_single_district(state, district)\n","\n","                time.sleep(2)  # Brief pause between districts\n","\n","            return self.data\n","\n","        except Exception as e:\n","            print(f\"Error in step-by-step scrape: {e}\")\n","            return self.data\n","        finally:\n","            if self.driver:\n","                self.driver.quit()\n","\n","    def select_language(self, language=\"English\"):\n","        \"\"\"Select language from first dropdown\"\"\"\n","        try:\n","            dropdowns = self.driver.find_elements(By.CSS_SELECTOR, \"select\")\n","            if dropdowns:\n","                lang_select = Select(dropdowns[0])\n","                lang_select.select_by_visible_text(language)\n","                print(f\"✓ Selected language: {language}\")\n","                time.sleep(3)\n","                return True\n","        except Exception as e:\n","            print(f\"Error selecting language: {e}\")\n","        return False\n","\n","    def select_state(self, state_name):\n","        \"\"\"Select state from dropdown\"\"\"\n","        try:\n","            dropdowns = self.driver.find_elements(By.CSS_SELECTOR, \"select\")\n","\n","            # Find state dropdown (usually second after language)\n","            state_dropdown = None\n","            for i, dropdown in enumerate(dropdowns[1:], 1):  # Skip first (language)\n","                select_obj = Select(dropdown)\n","                options = [opt.text.strip() for opt in select_obj.options if opt.get_attribute('value')]\n","\n","                if state_name in options:\n","                    state_dropdown = dropdown\n","                    print(f\"✓ Found state dropdown at index {i}\")\n","                    break\n","\n","            if state_dropdown:\n","                state_select = Select(state_dropdown)\n","                state_select.select_by_visible_text(state_name)\n","                print(f\"✓ Selected state: {state_name}\")\n","                time.sleep(4)  # Wait for districts to load\n","                return True\n","            else:\n","                print(f\"✗ State '{state_name}' not found in dropdowns\")\n","                return False\n","\n","        except Exception as e:\n","            print(f\"Error selecting state: {e}\")\n","            return False\n","\n","    def get_available_districts(self):\n","        \"\"\"Get list of available districts\"\"\"\n","        try:\n","            dropdowns = self.driver.find_elements(By.CSS_SELECTOR, \"select\")\n","\n","            # Find district dropdown (usually third)\n","            for dropdown in dropdowns[2:]:  # Skip language and state\n","                select_obj = Select(dropdown)\n","                options = select_obj.options\n","\n","                # Check if this looks like a district dropdown\n","                option_texts = [opt.text.strip() for opt in options if opt.get_attribute('value')]\n","\n","                # Filter out placeholder options\n","                valid_districts = [text for text in option_texts\n","                                 if not text.lower().startswith('select') and\n","                                    not text.lower().startswith('all') and\n","                                    text != '']\n","\n","                if valid_districts and len(valid_districts) > 5:  # Likely district dropdown\n","                    print(f\"✓ Found {len(valid_districts)} districts\")\n","                    return valid_districts  # CHANGED: Return ALL districts instead of limiting to 10\n","\n","            print(\"✗ No district dropdown found\")\n","            return []\n","\n","        except Exception as e:\n","            print(f\"Error getting districts: {e}\")\n","            return []\n","\n","    def process_single_district(self, state, district):\n","        \"\"\"Process a single district thoroughly\"\"\"\n","        try:\n","            # Re-select state and district (dropdowns refresh)\n","            print(f\"  Selecting {district}...\")\n","\n","            # Find and select state\n","            dropdowns = self.driver.find_elements(By.CSS_SELECTOR, \"select\")\n","            state_select = Select(dropdowns[1])  # Assuming second dropdown is state\n","            state_select.select_by_visible_text(state)\n","            time.sleep(2)\n","\n","            # Find and select district\n","            dropdowns = self.driver.find_elements(By.CSS_SELECTOR, \"select\")\n","            district_select = Select(dropdowns[2])  # Assuming third dropdown is district\n","            district_select.select_by_visible_text(district)\n","            time.sleep(4)  # Wait for data/mandis to load\n","\n","            print(f\"  ✓ Selected {district}, extracting data...\")\n","\n","            # First, try to extract data at district level\n","            extracted_count = len(self.data)\n","            self.extract_all_visible_data(state, district)\n","            new_extractions = len(self.data) - extracted_count\n","\n","            if new_extractions > 0:\n","                print(f\"  ✓ Extracted {new_extractions} records at district level\")\n","            else:\n","                print(\"  ! No data found at district level\")\n","\n","            # Then, check if there are mandis to select\n","            self.process_mandis_in_district(state, district)\n","\n","        except Exception as e:\n","            print(f\"  ✗ Error processing district {district}: {e}\")\n","\n","    def process_mandis_in_district(self, state, district):\n","        \"\"\"Process individual mandis within a district\"\"\"\n","        try:\n","            dropdowns = self.driver.find_elements(By.CSS_SELECTOR, \"select\")\n","\n","            if len(dropdowns) > 3:  # There might be a mandi dropdown\n","                mandi_select = Select(dropdowns[3])\n","                mandi_options = [opt for opt in mandi_select.options\n","                               if opt.get_attribute('value') and\n","                               not opt.text.strip().lower().startswith('select')]\n","\n","                if mandi_options:\n","                    print(f\"    Found {len(mandi_options)} mandis in {district}\")\n","\n","                    # CHANGED: Process ALL mandis instead of limiting to 3\n","                    for i, mandi_option in enumerate(mandi_options):\n","                        mandi_text = mandi_option.text.strip()\n","                        mandi_value = mandi_option.get_attribute('value')\n","\n","                        print(f\"      Processing mandi {i+1}/{len(mandi_options)}: {mandi_text}\")\n","\n","                        try:\n","                            # Re-select everything\n","                            dropdowns = self.driver.find_elements(By.CSS_SELECTOR, \"select\")\n","                            Select(dropdowns[1]).select_by_visible_text(state)\n","                            time.sleep(1)\n","                            Select(dropdowns[2]).select_by_visible_text(district)\n","                            time.sleep(2)\n","                            Select(dropdowns[3]).select_by_value(mandi_value)\n","                            time.sleep(3)\n","\n","                            # Extract data for this specific mandi\n","                            extracted_count = len(self.data)\n","                            self.extract_all_visible_data(state, district, mandi_text)\n","                            new_extractions = len(self.data) - extracted_count\n","\n","                            if new_extractions > 0:\n","                                print(f\"        ✓ Extracted {new_extractions} records for {mandi_text}\")\n","                            else:\n","                                print(f\"        ! No specific data found for {mandi_text}\")\n","\n","                        except Exception as e:\n","                            print(f\"        ✗ Error processing mandi {mandi_text}: {e}\")\n","                            continue\n","\n","        except Exception as e:\n","            print(f\"    Error processing mandis: {e}\")\n","\n","    def extract_all_visible_data(self, state, district, mandi=None):\n","        \"\"\"Extract all visible data from current page using multiple methods\"\"\"\n","\n","        # Method 1: Extract from tables\n","        self.extract_from_tables(state, district, mandi)\n","\n","        # Method 2: Extract from page text\n","        self.extract_from_page_text(state, district, mandi)\n","\n","        # Method 3: Check for specific elements\n","        self.extract_from_elements(state, district, mandi)\n","\n","    def extract_from_tables(self, state, district, mandi=None):\n","        \"\"\"Extract data from HTML tables\"\"\"\n","        try:\n","            tables = self.driver.find_elements(By.CSS_SELECTOR, \"table\")\n","\n","            for table in tables:\n","                rows = table.find_elements(By.CSS_SELECTOR, \"tr\")\n","                if len(rows) < 2:\n","                    continue\n","\n","                # Check if this table contains contact details\n","                table_text = table.text.lower()\n","                if any(keyword in table_text for keyword in ['mandi', 'contact', 'address', 'apmc']):\n","\n","                    record = {\n","                        'state': state,\n","                        'district': district,\n","                        'mandi_name': mandi or '',\n","                        'address': '',\n","                        'contact_details': ''\n","                    }\n","\n","                    for row in rows:\n","                        cells = row.find_elements(By.CSS_SELECTOR, \"td, th\")\n","                        if len(cells) >= 2:\n","                            key = cells[0].text.strip().lower()\n","                            value = cells[1].text.strip()\n","\n","                            if 'mandi' in key and 'name' in key:\n","                                record['mandi_name'] = value\n","                            elif 'address' in key:\n","                                record['address'] = value\n","                            elif 'contact' in key:\n","                                record['contact_details'] = value\n","                            elif 'state' in key and not record['state']:\n","                                record['state'] = value\n","\n","                    # Only add if we found meaningful data AND address is not empty\n","                    if (record['mandi_name'] or record['contact_details']) and record['address'].strip():\n","                        self.data.append(record)\n","                        print(f\"      ✓ Table extraction: {record['mandi_name'] or 'Unknown'}\")\n","\n","        except Exception as e:\n","            print(f\"      Error in table extraction: {e}\")\n","\n","    def extract_from_page_text(self, state, district, mandi=None):\n","        \"\"\"Extract data from plain page text\"\"\"\n","        try:\n","            body = self.driver.find_element(By.TAG_NAME, \"body\")\n","            page_text = body.text\n","\n","            # Look for contact details patterns\n","            if any(keyword in page_text.lower() for keyword in ['contact details', 'mandi name', 'apmc']):\n","\n","                # Try to find structured information\n","                lines = page_text.split('\\n')\n","                record = None\n","\n","                for line in lines:\n","                    line = line.strip()\n","                    if not line:\n","                        continue\n","\n","                    # Look for key indicators\n","                    if 'mandi name' in line.lower() and ':' in line:\n","                        if not record:\n","                            record = {\n","                                'state': state,\n","                                'district': district,\n","                                'mandi_name': mandi or '',\n","                                'address': '',\n","                                'contact_details': ''\n","                            }\n","\n","                        parts = line.split(':', 1)\n","                        if len(parts) == 2:\n","                            record['mandi_name'] = parts[1].strip()\n","\n","                    elif record and 'address' in line.lower() and ':' in line:\n","                        parts = line.split(':', 1)\n","                        if len(parts) == 2:\n","                            record['address'] = parts[1].strip()\n","\n","                    elif record and 'contact' in line.lower() and ':' in line:\n","                        parts = line.split(':', 1)\n","                        if len(parts) == 2:\n","                            record['contact_details'] = parts[1].strip()\n","\n","                if record and record['address'].strip() and (record['mandi_name'] or record['contact_details']):\n","                    self.data.append(record)\n","                    print(f\"      ✓ Text extraction: {record['mandi_name'] or 'Unknown'}\")\n","\n","        except Exception as e:\n","            print(f\"      Error in text extraction: {e}\")\n","\n","    def extract_from_elements(self, state, district, mandi=None):\n","        \"\"\"Extract data from specific page elements\"\"\"\n","        try:\n","            # Look for common result containers\n","            selectors = [\n","                '.result', '.contact-details', '.mandi-details',\n","                '.table-responsive', '.search-result', '.data-row',\n","                '[class*=\"result\"]', '[class*=\"contact\"]', '[class*=\"mandi\"]'\n","            ]\n","\n","            for selector in selectors:\n","                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)\n","\n","                for element in elements:\n","                    element_text = element.text.strip()\n","                    if len(element_text) > 20 and any(keyword in element_text.lower()\n","                                                     for keyword in ['mandi', 'contact', 'apmc']):\n","\n","                        # Only extract if we can find address information\n","                        if any(addr_keyword in element_text.lower() for addr_keyword in ['address', 'road', 'pin', 'market']):\n","                            record = {\n","                                'state': state,\n","                                'district': district,\n","                                'mandi_name': mandi or self.extract_mandi_name_from_text(element_text),\n","                                'address': self.extract_address_from_text(element_text),\n","                                'contact_details': self.extract_contact_from_text(element_text)\n","                            }\n","\n","                            # Only add if address is found\n","                            if record['address'].strip():\n","                                self.data.append(record)\n","                                print(f\"      ✓ Element extraction: {record['mandi_name'] or 'Unknown'}\")\n","                                break  # Only take first valid match per selector\n","\n","        except Exception as e:\n","            print(f\"      Error in element extraction: {e}\")\n","\n","    def extract_mandi_name_from_text(self, text):\n","        \"\"\"Extract mandi name from text\"\"\"\n","        lines = text.split('\\n')\n","        for line in lines:\n","            if 'mandi name' in line.lower() and ':' in line:\n","                parts = line.split(':', 1)\n","                if len(parts) == 2:\n","                    return parts[1].strip()\n","            elif 'apmc' in line.lower() and len(line) < 100:\n","                return line.strip()\n","        return ''\n","\n","    def extract_address_from_text(self, text):\n","        \"\"\"Extract address from text\"\"\"\n","        lines = text.split('\\n')\n","        for line in lines:\n","            if 'address' in line.lower() and ':' in line:\n","                parts = line.split(':', 1)\n","                if len(parts) == 2:\n","                    return parts[1].strip()\n","            elif any(keyword in line.lower() for keyword in ['road', 'pin', 'market', 'commiti']) and len(line) > 20:\n","                return line.strip()\n","        return ''\n","\n","    def extract_contact_from_text(self, text):\n","        \"\"\"Extract contact details from text\"\"\"\n","        lines = text.split('\\n')\n","        contact_info = []\n","\n","        for line in lines:\n","            line = line.strip()\n","            if 'contact' in line.lower() and ':' in line:\n","                parts = line.split(':', 1)\n","                if len(parts) == 2:\n","                    contact_info.append(parts[1].strip())\n","            elif '@' in line or any(char.isdigit() for char in line):\n","                # Look for email or phone patterns\n","                if len(line) < 50 and (line.count('@') == 1 or any(char.isdigit() for char in line)):\n","                    contact_info.append(line)\n","\n","        return ', '.join(contact_info)\n","\n","    def save_results(self):\n","        \"\"\"Save results to CSV with data cleaning\"\"\"\n","        if self.data:\n","            # Create DataFrame\n","            df = pd.DataFrame(self.data)\n","\n","            # Clean and filter data\n","            df = self.clean_data(df)\n","\n","            if len(df) > 0:\n","                filename = f\"enam_clean_data_{int(time.time())}.csv\"\n","                df.to_csv(filename, index=False)\n","                print(f\"\\n🎉 SUCCESS: Saved {len(df)} clean records to {filename}\")\n","\n","                # Show summary\n","                print(f\"\\nData Summary:\")\n","                print(f\"- Total records: {len(df)}\")\n","                print(f\"- States: {df['state'].nunique()}\")\n","                print(f\"- Districts: {df['district'].nunique()}\")\n","                print(f\"- Records with addresses: {df['address'].notna().sum()}\")\n","                print(f\"- Records with contact details: {df['contact_details'].notna().sum()}\")\n","\n","                print(f\"\\nSample records:\")\n","                for i, row in df.head().iterrows():\n","                    print(f\"{i+1}. {row['mandi_name']} | {row['district']} | Address: {row['address'][:50]}...\")\n","\n","                return df\n","            else:\n","                print(\"\\n❌ No valid data after cleaning\")\n","                return None\n","        else:\n","            print(\"\\n❌ No data extracted\")\n","            return None\n","\n","    def clean_data(self, df):\n","        \"\"\"Clean and filter the extracted data\"\"\"\n","        print(f\"Cleaning data: {len(df)} raw records\")\n","\n","        # Remove records without address\n","        df = df[df['address'].notna() & (df['address'].str.strip() != '')]\n","        print(f\"After address filter: {len(df)} records\")\n","\n","        # Remove duplicate records (same mandi_name + address)\n","        df = df.drop_duplicates(subset=['mandi_name', 'address'], keep='first')\n","        print(f\"After removing duplicates: {len(df)} records\")\n","\n","        # Clean text fields\n","        for col in ['mandi_name', 'address', 'contact_details']:\n","            if col in df.columns:\n","                df[col] = df[col].astype(str).str.strip()\n","                df[col] = df[col].replace('nan', '')\n","\n","        # Remove records where mandi_name is empty or just generic text\n","        invalid_mandi_names = ['', 'unknown', 'element_', 'debug_', 'nan', 'none']\n","        df = df[~df['mandi_name'].str.lower().isin(invalid_mandi_names)]\n","        df = df[~df['mandi_name'].str.lower().str.startswith('element_')]\n","        df = df[~df['mandi_name'].str.lower().str.startswith('debug_')]\n","        print(f\"After mandi name filter: {len(df)} records\")\n","\n","        # Ensure minimum data quality - must have either mandi_name or meaningful address\n","        df = df[\n","            (df['mandi_name'].str.len() > 3) |\n","            (df['address'].str.len() > 20)\n","        ]\n","        print(f\"After quality filter: {len(df)} records\")\n","\n","        # Reset index\n","        df = df.reset_index(drop=True)\n","\n","        return df\n","\n","# Modified usage function to scrape ALL districts and mandis\n","def run_focused_scraper(state=\"Maharashtra\", max_districts=None):\n","    \"\"\"Run the focused scraper for ALL districts and mandis\"\"\"\n","    scraper = FocusedEnamScraper()\n","    try:\n","        data = scraper.scrape_step_by_step(state, max_districts)\n","        return scraper.save_results()\n","    except Exception as e:\n","        print(f\"Scraper failed: {e}\")\n","        return None\n","\n","# Run it for ALL districts and mandis in Gujarat\n","if __name__ == \"__main__\":\n","    print(\"🚀 Starting complete Gujarat eNAM data extraction...\")\n","    print(\"⚠️  This will take considerable time as it processes ALL districts and mandis\")\n","    df = run_focused_scraper(\"Gujarat\", max_districts=None)  # None means ALL districts"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOkJs/xswRLHJH6BABSm9pU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}